from llama_index.core import Settings

Settings.chunk_size = 1024
Settings.chunk_overlap = 50